{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Environnement de Kaggle qui permet de ne pas utiliser le cpu et la ram de notre machine et qui a deja plusieurs librairies pre-installés\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "        \n",
    "DIR_PATH = '/kaggle/input/covid19-radiography-database/COVID-19 Radiography Database/'\n",
    "CLASSES = ['COVID', 'NORMAL', 'Viral Pneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for dirname, _, filenames in os.walk(DIR_PATH): # os.walk retourne premierement le Path puis les directories sous le path puis tous les fichiers du path donc dirname ici sont covid,normal et vp et filenames sont les images sous chaque dirname.\n",
    "    for file in filenames:\n",
    "        if 'png' in file:\n",
    "            image = cv2.imread(os.path.join(dirname, file))\n",
    "            image = cv2.resize(image, (64, 64)) / 255.0 # we resize the image to 64 height and 64 width, we divide by 255 to obtain normalized values between 0 and 1(bcs pixels of the image are between 0 and 255), so that the optimizer doesnt explode and be efficient\n",
    "            label = CLASSES.index(os.path.split(dirname)[-1]) # label sera 0 ou 1 ou 2 un int donc\n",
    "            #print(os.path.split(dirname)[-1]) : retourne '/kaggle/input/covid19-radiography-database/COVID-19 Radiography Database', 'NORMAL' en premier donc le -1 est pour prendre le dernier élément de ce retour qui est 'NORMAL'\n",
    "            all_data.append([image, label])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for img, lbl in all_data:\n",
    "    X.append(img)\n",
    "    y.append(lbl)\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premier modèle avec 9 couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape de l'image (64,64,3) :(width,height,RGB channels),on a le 3 car images couleurs\n",
    "model_1 = models.Sequential() # Le model est sequentiel c'est a dire les données rentrent batch par batch sequence par sequence \n",
    "    \n",
    "model_1.add(layers.Conv2D(30, (5, 5), input_shape=(64, 64, 3), activation='relu')) # Relu fonction linéaire donc elle permet de converger plus rapidement,on sélectionne 30 features de l'image,notamment détection des edges avec une matrice 5*5(filtrage)\n",
    "model_1.add(layers.MaxPooling2D(pool_size=(2, 2))) # Reduction de la dimension de l'image par le biais d'une matrice 2*2 où on garde le max\n",
    "    \n",
    "model_1.add(layers.Conv2D(15, (3, 3), activation='relu')) # on sélectionne 15 features de l'image,avec une matrice 3*3 (filtrage)\n",
    "model_1.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "model_1.add(layers.Dropout(0.2)) # on perd 20% des neurones du réseau afin d'éviter un over-fitting.\n",
    "model_1.add(layers.Flatten()) # transforme en image qui a une shape à 3 dimensions en un vecteur 1 dimension\n",
    "    \n",
    "model_1.add(layers.Dense(128, activation='relu')) # couche avec 128 neuronnes\n",
    "model_1.add(layers.Dense(50, activation='relu')) # couche avec 50 neuronnes\n",
    "model_1.add(layers.Dense(3, activation='softmax')) # on utilise la fonction softmax car elle permet d'avoir des valeurs en output entre [0,1] ce qui permet une classification avec n'importe quel nbr de classes ici on en a plus que 2 (cas non binaires)\n",
    "    \n",
    "# Compile model\n",
    "model_1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])\n",
    "#Adam optimizer pour optimiser nos poids ,SparseCategoricalCrossentropyloss function when there are two or more label classes. We expect labels to be provided as integers, which is our case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model_1.fit(X_train, y_train, epochs=30, \n",
    "                    validation_data=(X_test, y_test),batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1 = model_1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Final CNN accuracy of model 1: ', scores_1[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième modèle avec 7 couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the CNN\n",
    "#There is also a graph option but we'll use sequential ANN Model\n",
    "model_2 = models.Sequential()\n",
    "\n",
    "#step 1 - Convolution\n",
    "#creating the feature map by using feature detector from ınput image\n",
    "\n",
    "model_2.add(layers.Convolution2D(32,3,3, input_shape=(64,64,3), activation='relu'))\n",
    "#32 Feature maps&detetctors uses 3 by 3 matrices, we can put 128 in the powerful machines\n",
    "\n",
    "#step -2 Pooling\n",
    "model_2.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "#second convolution and pooling steps.\n",
    "model_2.add(layers.Convolution2D(32,3,3, input_shape=(64,64,3), activation='relu'))\n",
    "\n",
    "model_2.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "#step -3 Flattening\n",
    "model_2.add(layers.Flatten())\n",
    "\n",
    "#step-4 Full connection step\n",
    "model_2.add(layers.Dense(64, activation = 'relu'))\n",
    "model_2.add(layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "\n",
    "model_2.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model_2.fit(X_train, y_train, epochs=30, \n",
    "                    validation_data=(X_test, y_test),batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2 = model_2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Final CNN accuracy of model 2: ', scores_2[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On remarque donc que le premier modèle est le meilleur en terme d'accuracy , réssayons son apprentissage avec cette fois-ci sgd en optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape de l'image (64,64,3) :(width,height,RGB channels),on a le 3 car images couleurs\n",
    "model_1_sgd = models.Sequential()\n",
    "    \n",
    "model_1_sgd.add(layers.Conv2D(30, (5, 5), input_shape=(64, 64, 3), activation='relu')) # Relu fonction linéaire donc elle permet de converger plus rapidement,on sélectionne 30 features de l'image,notamment détection des edges avec une matrice 5*5(filtrage)\n",
    "model_1_sgd.add(layers.MaxPooling2D(pool_size=(2, 2))) # Reduction de la dimension de l'image par le biais d'une matrice 2*2 où on garde le max\n",
    "    \n",
    "model_1_sgd.add(layers.Conv2D(15, (3, 3), activation='relu')) # on sélectionne 15 features de l'image,avec une matrice 3*3 (filtrage)\n",
    "model_1_sgd.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "model_1_sgd.add(layers.Dropout(0.2)) # on perd 20% des neurones du réseau afin d'éviter un over-fitting.\n",
    "model_1_sgd.add(layers.Flatten()) # transforme en image qui a une shape à 3 dimensions en un vecteur 1 dimension\n",
    "    \n",
    "model_1_sgd.add(layers.Dense(128, activation='relu')) # couche avec 128 neuronnes\n",
    "model_1_sgd.add(layers.Dense(50, activation='relu')) # couche avec 50 neuronnes\n",
    "model_1_sgd.add(layers.Dense(3, activation='softmax')) # on utilise la fonction softmax car elle permet d'avoir des valeurs en output entre [0,1] ce qui permet une classification avec n'importe quel nbr de classes ici on en a plus que 2 (cas non binaires)\n",
    "    \n",
    "\n",
    "model_1_sgd.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1_sgd = model_1_sgd.fit(X_train, y_train, epochs=30, \n",
    "                    validation_data=(X_test, y_test),batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1_sgd = model_1_sgd.evaluate(X_test, y_test, verbose=0)\n",
    "print('Final CNN accuracy of model 1 with sgd: ', scores_1_sgd[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comme on peut le voir notre premier modèle est  plus efficace avec adam en optimizer car l'optimizer adam a tendance a convergé plus rapidement que le sgd et vu qu'ici le nombre d'epochs n'est que de 30 alors adam est plus efficace. Mais en général et adam et sgd optimizer restent très populaires car ils peuvent êtres utilisés dans la plupart des cas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We plot the loss and accuracy of our first model over 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_loss(results, epochs):\n",
    " acc = results.history['accuracy']\n",
    " loss = results.history['loss']\n",
    " val_acc = results.history['val_accuracy']\n",
    " val_loss = results.history['val_loss']\n",
    " plt.figure(figsize=(15, 5))\n",
    " plt.subplot(121)\n",
    " plt.plot( acc[1:], label='Train_acc')\n",
    " plt.plot( val_acc[1:], label='Test_acc')\n",
    " plt.title('Accuracy over ' + str(epochs) + ' Epochs', size=15)\n",
    " plt.legend()\n",
    " plt.grid(True)\n",
    " plt.subplot(122)\n",
    " plt.plot( loss[1:], label='Train_loss')\n",
    " plt.plot( val_loss[1:], label='Test_loss')\n",
    " plt.title('Loss over ' + str(epochs) +  ' Epochs', size=15)\n",
    " plt.legend()\n",
    " plt.grid(True)\n",
    " plt.show()\n",
    " \n",
    "plot_acc_loss(history_1, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We plot the loss and accuracy of our second model over 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss(history_2, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We plot the loss and accuracy of our first model this time with sgd as optimizer over 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss(history_1_sgd, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This time we will hot-encode our output to use a different loss function with our first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we had labels as integers : 0 : covid , 1 : normal and 2 : viral pneumonia for example , now our labels will be vectors: (1,0,0) for example for covid. This will give us the possibility to use a different loss function and see the difference between having and int as outpout and a vector. Because sometimes using integers as output can give higher weights to the category with the higher number and this could mess with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train_cnn = np_utils.to_categorical(y_train)\n",
    "y_test_cnn = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape de l'image (64,64,3) :(width,height,RGB channels),on a le 3 car images couleurs\n",
    "model_1_encode = models.Sequential()\n",
    "    \n",
    "model_1_encode.add(layers.Conv2D(30, (5, 5), input_shape=(64, 64, 3), activation='relu',)) # Relu fonction linéaire donc elle permet de converger plus rapidement,on sélectionne 30 features de l'image,notamment détection des edges avec une matrice 5*5(filtrage)\n",
    "model_1_encode.add(layers.MaxPooling2D(pool_size=(2, 2))) # Reduction de la dimension de l'image par le biais d'une matrice 2*2 où on garde le max\n",
    "    \n",
    "model_1_encode.add(layers.Conv2D(15, (3, 3), activation='relu')) # on sélectionne 15 features de l'image,avec une matrice 3*3 (filtrage)\n",
    "model_1_encode.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "model_1_encode.add(layers.Dropout(0.2)) # on perd 20% des neurones du réseau afin d'éviter un over-fitting.\n",
    "model_1_encode.add(layers.Flatten()) # transforme en image qui a une shape à 3 dimensions en un vecteur 1 dimension\n",
    "    \n",
    "model_1_encode.add(layers.Dense(128, activation='relu')) # couche avec 128 neuronnes\n",
    "model_1_encode.add(layers.Dense(50, activation='relu')) # couche avec 50 neuronnes\n",
    "model_1_encode.add(layers.Dense(3, activation='softmax')) # on utilise la fonction softmax car elle permet d'avoir des valeurs en output entre [0,1] ce qui permet une classification avec n'importe quel nbr de classes ici on en a plus que 2 (cas non binaires)\n",
    "    \n",
    "# Compile model\n",
    "model_1_encode.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#Adam optimizer pour optimiser nos poids ,CategoricalCrossentropyloss function when there are two or more label classes. We expect labels to be provided as vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1_encode = model_1_encode.fit(X_train, y_train_cnn, epochs=30, \n",
    "                    validation_data=(X_test, y_test_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1_encode = model_1_encode.evaluate(X_test, y_test_cnn, verbose=0)\n",
    "print('Final CNN accuracy of model 1 with hot encoding: ', scores_1_encode[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss(history_1_encode, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some predictions with external data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model with sgd optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/Covid19.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image) # converts image to array\n",
    "test_image = np.expand_dims(test_image, axis = 0) # adds dimension because convolutional layer expects 4 dimensions (the added dimension is the batch size dimension to feed N number of data points at time to the model)\n",
    "output = model_1_sgd.predict(test_image) # return vector with probabilities for each class\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)]) # max so that it takes the one which is the prediction and returns the name of the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/covid19_2.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_1_sgd.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/healthy.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_1_sgd.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/vp2.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_1_sgd.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/Covid19.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_2.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/covid19_2.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_2.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/healthy.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_2.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/healthy2.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_2.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/healthy4.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_2.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/vp2.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_2.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model with adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/Covid19.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_1.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/covid19_2.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_1.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/healthy.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_1.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/vp2.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_1.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firs model with one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/Covid19.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_1_encode.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/healthy.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "output = model_1_encode.predict(test_image)\n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('/kaggle/input/test-cnn-covid/vp2.jpeg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image, axis = 0) \n",
    "output = model_1_encode.predict(test_image) \n",
    "print(\"Predicted:\", CLASSES[np.argmax(output)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We see that since the dataset is too small we can't really exploit the results of our models we will need way more images in order to avoid overfitting and to train our models properly, but in terms of predictions the second model is the most interesting one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
